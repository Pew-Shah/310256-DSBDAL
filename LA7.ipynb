{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d12bf215-3f65-44f2-bf1d-800e0d101344",
   "metadata": {},
   "source": [
    "LA7:Text Analytics\n",
    "1. Extract Sample document and apply following document preprocessing methods:\n",
    "Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.\n",
    "2. Create representation of document by calculating Term Frequency and Inverse Document\n",
    "Frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28b3ac49-bc07-4cfe-b21c-7d8dd63ddb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"The local library recently underwent a renovation, and it's so much better now! \\\n",
    "        The aisles are wider, making browsing for books much easier. \\\n",
    "        They've also added a comfortable seating area with plenty of natural light, perfect for curling up with a good read.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b357cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\soham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"the local library recently underwent a renovation, and it's so much better now!\",\n",
       " 'the aisles are wider, making browsing for books much easier.',\n",
       " \"they've also added a comfortable seating area with plenty of natural light, perfect for curling up with a good read.\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "sents = sent_tokenize(corpus)\n",
    "\n",
    "pre = []\n",
    "\n",
    "for i in sents:\n",
    "    pre.append(i.lower())\n",
    "    \n",
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a995d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the local library recently underwent a renovation and its so much better now',\n",
       " 'the aisles are wider making browsing for books much easier',\n",
       " 'theyve also added a comfortable seating area with plenty of natural light perfect for curling up with a good read']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sample = []\n",
    "for a in pre:\n",
    "    sample.append(re.sub(\"[^a-z ]\", '', a)); \n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5d8d28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'local',\n",
       "  'library',\n",
       "  'recently',\n",
       "  'underwent',\n",
       "  'a',\n",
       "  'renovation',\n",
       "  'and',\n",
       "  'its',\n",
       "  'so',\n",
       "  'much',\n",
       "  'better',\n",
       "  'now'],\n",
       " ['the',\n",
       "  'aisles',\n",
       "  'are',\n",
       "  'wider',\n",
       "  'making',\n",
       "  'browsing',\n",
       "  'for',\n",
       "  'books',\n",
       "  'much',\n",
       "  'easier'],\n",
       " ['theyve',\n",
       "  'also',\n",
       "  'added',\n",
       "  'a',\n",
       "  'comfortable',\n",
       "  'seating',\n",
       "  'area',\n",
       "  'with',\n",
       "  'plenty',\n",
       "  'of',\n",
       "  'natural',\n",
       "  'light',\n",
       "  'perfect',\n",
       "  'for',\n",
       "  'curling',\n",
       "  'up',\n",
       "  'with',\n",
       "  'a',\n",
       "  'good',\n",
       "  'read']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "words = []\n",
    "for b in sample:\n",
    "    words.append(word_tokenize(b))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e4d32cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['local', 'library', 'recently', 'underwent', 'renovation', 'much', 'better'], ['aisles', 'wider', 'making', 'browsing', 'books', 'much', 'easier'], ['theyve', 'also', 'added', 'comfortable', 'seating', 'area', 'plenty', 'natural', 'light', 'perfect', 'curling', 'good', 'read']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\soham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "cleaned = []\n",
    "\n",
    "for c in words:\n",
    "    cleaned.append([w for w in c if w not in stopwords.words(\"english\")])\n",
    "print(cleaned)\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37ccbc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['local', 'librari', 'recent', 'underw', 'renov', 'much', 'better'],\n",
       " ['aisl', 'wider', 'make', 'brows', 'book', 'much', 'easier'],\n",
       " ['theyv',\n",
       "  'also',\n",
       "  'ad',\n",
       "  'comfort',\n",
       "  'seat',\n",
       "  'area',\n",
       "  'plenti',\n",
       "  'natur',\n",
       "  'light',\n",
       "  'perfect',\n",
       "  'curl',\n",
       "  'good',\n",
       "  'read']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "ss = SnowballStemmer('english')\n",
    "\n",
    "stemmed = []\n",
    "for d in cleaned:\n",
    "    stemmed.append([ss.stem(word) for word in d])\n",
    "stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15cb903a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\soham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('local', 'JJ'),\n",
       "  ('library', 'NN'),\n",
       "  ('recently', 'RB'),\n",
       "  ('underwent', 'JJ'),\n",
       "  ('renovation', 'NN'),\n",
       "  ('much', 'RB'),\n",
       "  ('better', 'RBR')],\n",
       " [('aisles', 'NNS'),\n",
       "  ('wider', 'VBP'),\n",
       "  ('making', 'VBG'),\n",
       "  ('browsing', 'VBG'),\n",
       "  ('books', 'NNS'),\n",
       "  ('much', 'RB'),\n",
       "  ('easier', 'JJR')],\n",
       " [('theyve', 'NN'),\n",
       "  ('also', 'RB'),\n",
       "  ('added', 'VBD'),\n",
       "  ('comfortable', 'JJ'),\n",
       "  ('seating', 'VBG'),\n",
       "  ('area', 'NN'),\n",
       "  ('plenty', 'JJ'),\n",
       "  ('natural', 'JJ'),\n",
       "  ('light', 'NN'),\n",
       "  ('perfect', 'NN'),\n",
       "  ('curling', 'VBG'),\n",
       "  ('good', 'JJ'),\n",
       "  ('read', 'NN')]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "tags = []    \n",
    "for e in cleaned:\n",
    "    tags.append(pos_tag(e))\n",
    "tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a00304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\soham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['local library recently underwent renovation much well',\n",
       " 'aisle wider make browse book much easy',\n",
       " 'theyve also add comfortable seat area plenty natural light perfect curl good read']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lm = WordNetLemmatizer()\n",
    "lemmatized = []\n",
    "for f in tags:\n",
    "    lemmatized.append(\" \".join([lm.lemmatize(word[0], pos=get_wordnet_pos(word[1])) for word in f]))\n",
    "lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b14eae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'local': 12, 'library': 10, 'recently': 19, 'underwent': 23, 'renovation': 20, 'much': 14, 'well': 24, 'aisle': 1, 'wider': 25, 'make': 13, 'browse': 5, 'book': 4, 'easy': 8, 'theyve': 22, 'also': 2, 'add': 0, 'comfortable': 6, 'seat': 21, 'area': 3, 'plenty': 17, 'natural': 15, 'light': 11, 'perfect': 16, 'curl': 7, 'good': 9, 'read': 18}\n",
      "  (0, 24)\t0.3898880096169543\n",
      "  (0, 14)\t0.29651988085384556\n",
      "  (0, 20)\t0.3898880096169543\n",
      "  (0, 23)\t0.3898880096169543\n",
      "  (0, 19)\t0.3898880096169543\n",
      "  (0, 10)\t0.3898880096169543\n",
      "  (0, 12)\t0.3898880096169543\n",
      "  (1, 8)\t0.3898880096169543\n",
      "  (1, 4)\t0.3898880096169543\n",
      "  (1, 5)\t0.3898880096169543\n",
      "  (1, 13)\t0.3898880096169543\n",
      "  (1, 25)\t0.3898880096169543\n",
      "  (1, 1)\t0.3898880096169543\n",
      "  (1, 14)\t0.29651988085384556\n",
      "  (2, 18)\t0.2773500981126146\n",
      "  (2, 9)\t0.2773500981126146\n",
      "  (2, 7)\t0.2773500981126146\n",
      "  (2, 16)\t0.2773500981126146\n",
      "  (2, 11)\t0.2773500981126146\n",
      "  (2, 15)\t0.2773500981126146\n",
      "  (2, 17)\t0.2773500981126146\n",
      "  (2, 3)\t0.2773500981126146\n",
      "  (2, 21)\t0.2773500981126146\n",
      "  (2, 6)\t0.2773500981126146\n",
      "  (2, 0)\t0.2773500981126146\n",
      "  (2, 2)\t0.2773500981126146\n",
      "  (2, 22)\t0.2773500981126146\n",
      "\n",
      "add : 1.6931471805599454\n",
      "aisle : 1.6931471805599454\n",
      "also : 1.6931471805599454\n",
      "area : 1.6931471805599454\n",
      "book : 1.6931471805599454\n",
      "browse : 1.6931471805599454\n",
      "comfortable : 1.6931471805599454\n",
      "curl : 1.6931471805599454\n",
      "easy : 1.6931471805599454\n",
      "good : 1.6931471805599454\n",
      "library : 1.6931471805599454\n",
      "light : 1.6931471805599454\n",
      "local : 1.6931471805599454\n",
      "make : 1.6931471805599454\n",
      "much : 1.2876820724517808\n",
      "natural : 1.6931471805599454\n",
      "perfect : 1.6931471805599454\n",
      "plenty : 1.6931471805599454\n",
      "read : 1.6931471805599454\n",
      "recently : 1.6931471805599454\n",
      "renovation : 1.6931471805599454\n",
      "seat : 1.6931471805599454\n",
      "theyve : 1.6931471805599454\n",
      "underwent : 1.6931471805599454\n",
      "well : 1.6931471805599454\n",
      "wider : 1.6931471805599454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorized_docs = vectorizer.fit_transform(lemmatized)\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorized_docs)\n",
    "print()\n",
    "\n",
    "for term,idf in zip(vectorizer.get_feature_names_out(),vectorizer.idf_):\n",
    "    print(term,\":\",idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d369299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7fc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
